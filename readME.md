## LAB 8  solution by Clayton Sibanda


Question 1: How many iterations does it take for the Value Iteration algorithm
to converge? In an output text file list the optimal values (V
∗for eachstate).

Answer:
4 iterations

Question 2: Assume we start in state s1, give the states that form the
optimal policy (π∗) to reach the terminal state (s3).

Answer:
S1 -> S2 -> S5-> S6-> S3


Question 3: Is it possible to change the reward function function so that
V∗ changes, but the optimal policy (π∗) remains unchanged?

Answer:
: Yes. Double each each immediate reward. Then V∗ is also doubled and π ∗ remains unchanged



